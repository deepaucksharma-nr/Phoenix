receivers:
  hostmetrics:
    collection_interval: 10s
    root_path: /hostfs
    scrapers:
      process:
        include:
          match_type: regexp
          names: [".*"]
        exclude:
          names: ["otelcol", "gopsutil_*"]
        metrics:
          process.cpu.time:
            enabled: true
          process.cpu.utilization:
            enabled: true
          process.memory.physical:
            enabled: true
          process.memory.virtual:
            enabled: true
          process.disk.io:
            enabled: true
          process.threads:
            enabled: true
          process.open_file_descriptors:
            enabled: true

processors:
  memory_limiter:
    check_interval: 1s
    limit_percentage: 80
    spike_limit_percentage: 20
  
  cumulativetodelta:
    include:
      metrics:
        - process.cpu.time
        - process.disk.io
  
  resourcedetection/system:
    detectors: [env, system, ec2, gcp, azure]
    system:
      hostname_sources: ["os"]
    timeout: 2s
    override: false
  
  resource/add_experiment_info:
    attributes:
      - key: phoenix.experiment.id
        value: ${PHOENIX_EXPERIMENT_ID}
        action: insert
      - key: phoenix.variant
        value: ${PHOENIX_VARIANT}
        action: insert
      - key: node.name
        value: ${NODE_NAME}
        action: upsert
  
  transform/add_resource_score:
    metric_statements:
      - context: datapoint
        statements:
          # Calculate a combined resource score (CPU% * 10 + Memory MB / 1000000)
          - set(attributes["resource_score"], 
              attributes["process.cpu.utilization"] * 10 + 
              attributes["process.memory.physical"] / 1000000)
            where name == "process.cpu.utilization" or name == "process.memory.physical"
  
  # Note: This is a conceptual top-k filter. In practice, you'd need a custom processor
  # or use sampling techniques to achieve true top-k behavior
  filter/topk_simulation:
    metrics:
      datapoint:
        # Keep processes with high resource usage or critical processes
        - 'attributes["process.cpu.utilization"] > 5.0 or attributes["process.memory.physical"] > 100000000'
        # Also keep database and web server processes regardless of usage
        - 'attributes["process.executable.name"] matches "^(postgres|mysql|mongodb|redis|nginx|apache|java|python|node)"'
  
  # Alternative approach: Use probabilistic sampling with bias toward high-resource processes
  probabilistic_sampler/topk:
    sampling_percentage: 20.0  # Keep only 20% of processes
    # Note: Real implementation would need attribute-based sampling
  
  batch:
    send_batch_size: 500  # Smaller batches due to reduced data volume
    timeout: 15s
    send_batch_max_size: 1000

exporters:
  otlphttp/newrelic:
    endpoint: ${NEW_RELIC_OTLP_ENDPOINT:-https://otlp.nr-data.net}
    headers:
      api-key: ${NEW_RELIC_API_KEY}
    compression: gzip
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
    sending_queue:
      enabled: true
      num_consumers: 2
      queue_size: 500
  
  prometheus:
    endpoint: 0.0.0.0:8888
    namespace: phoenix
    const_labels:
      experiment_id: ${PHOENIX_EXPERIMENT_ID}
      variant: ${PHOENIX_VARIANT}
      strategy: topk
    resource_to_telemetry_conversion:
      enabled: true
    enable_open_metrics: true

extensions:
  health_check:
    endpoint: 0.0.0.0:13133
  
  pprof:
    endpoint: 0.0.0.0:1777
  
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]
  pipelines:
    metrics:
      receivers: [hostmetrics]
      processors:
        - memory_limiter
        - cumulativetodelta
        - resourcedetection/system
        - resource/add_experiment_info
        - transform/add_resource_score
        - filter/topk_simulation
        - batch
      exporters: [otlphttp/newrelic, prometheus]
  
  telemetry:
    logs:
      level: info
      output_paths: ["stdout"]
      error_output_paths: ["stderr"]
    metrics:
      level: detailed
      address: 0.0.0.0:8889
      
# Template Metadata
metadata:
  name: "Process Top-K Filter v1"
  description: "Reduces process metrics volume by keeping only the top resource consumers and critical processes"
  strategy: "topk"
  expected_reduction: "60-80%"
  use_cases:
    - "High-cardinality environments with many idle processes"
    - "Focus on resource-intensive applications"
    - "Kubernetes clusters with many short-lived pods"
  parameters:
    k_value:
      description: "Number of top processes to keep (simulated via sampling)"
      default: "20% sampling"
      configurable: true
    min_cpu_threshold:
      description: "Minimum CPU utilization to always include"
      default: "5.0%"
      configurable: true
    min_memory_threshold:
      description: "Minimum memory usage to always include"
      default: "100MB"
      configurable: true