apiVersion: v1
kind: ServiceMonitor
metadata:
  name: otel-collector-main
  labels:
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: otel-collector-main
  endpoints:
  - port: metrics-full
    interval: 15s
    path: /metrics
  - port: metrics-opt
    interval: 15s
    path: /metrics
  - port: metrics-exp
    interval: 15s
    path: /metrics

---
apiVersion: v1
kind: ServiceMonitor
metadata:
  name: otel-collector-observer
  labels:
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: otel-collector-observer
  endpoints:
  - port: metrics
    interval: 15s
    path: /metrics

---
apiVersion: v1
kind: PrometheusRule
metadata:
  name: phoenix-alerts
  labels:
    prometheus: kube-prometheus
spec:
  groups:
  - name: phoenix.rules
    interval: 30s
    rules:
    - alert: HighCardinality
      expr: phoenix_observer_kpi_store_phoenix_pipeline_output_cardinality_estimate > 30000
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High cardinality detected in {{ $labels.pipeline }}"
        description: "Pipeline {{ $labels.pipeline }} has cardinality of {{ $value }}"
    
    - alert: CollectorDown
      expr: up{job=~"otel-collector.*"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Collector {{ $labels.instance }} is down"
        description: "OpenTelemetry collector {{ $labels.instance }} has been down for more than 5 minutes"
    
    - alert: HighMemoryUsage
      expr: process_resident_memory_bytes{job=~"otel-collector.*"} / 1024 / 1024 / 1024 > 1.5
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage on {{ $labels.instance }}"
        description: "Collector {{ $labels.instance }} is using {{ $value }}GB of memory"