# Phoenix Prometheus Configuration
# This configuration scrapes metrics from Pushgateway where agents push their data

global:
  scrape_interval: 15s          # How often to scrape targets
  evaluation_interval: 15s      # How often to evaluate rules
  scrape_timeout: 10s          # Timeout for scraping
  
  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager)
  external_labels:
    environment: 'production'
    phoenix_instance: 'single-vm'

# Load rules once and periodically evaluate them
rule_files:
  - '/etc/prometheus/rules/*.yml'

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets: []
          # - 'alertmanager:9093'

# Scrape configurations
scrape_configs:
  # Scrape Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          service: 'prometheus'

  # Scrape Pushgateway for agent metrics
  - job_name: 'pushgateway'
    honor_labels: true           # Use labels from pushed metrics
    scrape_interval: 15s
    static_configs:
      - targets: ['pushgateway:9091']
        labels:
          service: 'pushgateway'
    
    # Keep metrics fresh - remove stale agent metrics
    metric_relabel_configs:
      # Drop pushgateway's own metrics to reduce noise
      - source_labels: [__name__]
        regex: 'pushgateway_.*'
        action: drop
      
      # Keep only Phoenix-specific metrics
      - source_labels: [__name__]
        regex: 'phoenix_.*|otel_.*|process_.*|go_.*'
        action: keep

  # Scrape Phoenix API metrics
  - job_name: 'phoenix-api'
    scrape_interval: 30s
    static_configs:
      - targets: ['api:8080']
        labels:
          service: 'phoenix-api'
    metrics_path: '/metrics'

  # Optional: Scrape node exporters if deployed on agents
  - job_name: 'node'
    scrape_interval: 30s
    file_sd_configs:
      - files:
          - '/etc/prometheus/targets/nodes/*.yml'
        refresh_interval: 5m

# Remote write configuration (optional - for long-term storage)
# remote_write:
#   - url: "https://metrics-storage.example.com/write"
#     remote_timeout: 30s
#     queue_config:
#       capacity: 10000
#       max_shards: 10
#       max_samples_per_send: 5000

# Recording rules for performance
# These pre-calculate expensive queries
recording_rules:
  - name: phoenix_aggregations
    interval: 30s
    rules:
      # Total active agents
      - record: phoenix:active_agents:count
        expr: count(time() - phoenix_agent_last_heartbeat < 60)
      
      # Total metrics processed per second
      - record: phoenix:metrics:rate5m
        expr: sum(rate(phoenix_processed_series[5m]))
      
      # Cost savings rate
      - record: phoenix:cost_savings:rate1h
        expr: sum(rate(phoenix_cost_savings_total[1h]))
      
      # Agent health percentage
      - record: phoenix:agent_health:percentage
        expr: |
          100 * (
            count(time() - phoenix_agent_last_heartbeat < 60) 
            / 
            count(phoenix_agent_info)
          )